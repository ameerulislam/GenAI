Tutorial Link: https://www.youtube.com/watch?v=zizonToFXDs

# Large Language Models (LLMs) are subset of deep learning
Large, general-purpose language models can be pre-trained and then fine-tuned for specific purposes

Pre-trained to solve:
- Text Classification
- Question answering
- Document summarization
- Text Generation
Then the model can be tailred to solve specific problems (fine tuning) in different fields, like
- Retail
- Finance
- Entertainment
etc
Trained with a relatively small size of field datasets

Large 
- Large training dataset
- Large number of parameters
 General purpose
- commonallity of human languages
- Resource restriction
Pre-trained and fine-tuned
few shot
zero shot

PaLM (Pathways Language Model)
is dense decoder only model
540 Billion parameters
Leverages the new pathway system
paythway is new AI architecture that handles many tasks at once. Learn new tasks quickly and have better understanding of the world.
Orchestrates distributed computation for accelerators

Input -> Encodin Component -> Decoding Component -> Output

What is Question Answering in Natural Language Processing?
Question answering (QA) is a subfield of natural language processing that deals with the task of automatically answering questions posed in natural language.

Question Answering models are able to retrive the answer to a question from a given text. This is useful for searching for an answer in a document. Depending on the model used, the answer can be directly extracted from text or generated from scratch. 

Generative QA
Generates free text directly based on the context
It leverages text generation models
No need for domain knowledge

Prompt Design: promots involve instructions and context passed to a language model to achieve a desired task.

Prompt Engineering: Prompt engineering is the practice of developing and optimizing prompts to efficiently use language models for a variety of applications.

## There are 3 main kinds of LLM
each needs prompting in a different way

- Generic (or Raw) Language Models | These predict the next word (technically token) based on the language in the training data.

- Instruction tuned | Trained to predict a response to the instructions given in the input

- Dialog Tuned| Trained to have a dialog by predicting the next response

## Tuning
The process of adapting a model to a new domain or set of custom use cases by training the model on new data. For example, we may collect training data and "tune" the LLM specifically for the legal or medical domain.

## Fine Tuning
Bring your own dataset of and retrain the model by tuning every weight in the LLM. This requires a big training job (like really big) and hosting your own fine-tuned model.



