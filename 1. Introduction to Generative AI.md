- generative AI generates new data/ content
- GenAI is subset of Deep Learning
- It uses Artificial Neural Networks
- Can process both labeled and unlabeled data, using supervised, unsupervised and semi-supervised methods.

- LLM is also subset of deep learning

Deep Learning models are 2 types
- Discriminative 
-- Used to classify or predict
-- Typically trained on a dataset of labeled data
-- Learns the relationship between the features of the data points and the labels

- Generative
-- Generates new data that is similar to data it was trained on
-- understands distribution of data and how likely a given example is
-- Predict next word in a sequence

Summary
Generative model can generate new instances
Discriminative models distinguish between different data kinds of data instances

---
Predictive ML model 
- learns relationship between data and label

GenAI Model
- learns patterns in unstructured content

---
Not GenAI when y is a:
- Number
- Discrete
- Class
- Probability

Is GenAI when y is:
- Natural Language
- Image
- Audio

-----

Classical Supervised & Unsupervised Learning

X = Training Code, Labeled data
fn = Model Building
y = Predict, Classify or Cluster

----

Gen AI Supervise, Semi-Supervised & Unsupervised Leraning

X = Training code / Labeled data/ Unlabeled data
fn = Foundation Model
y = Text Generation/ Code Generation/ Image Generation

----------
What is Generative AI?
- GenAI is a type of Artificial Intelligence that creates new content based on what it has learned from existing content.
- The process of learning from existing content is called training and results in the creation of a statistical model.
- When given a prompt, GenAi uses this statistical model to predict what an expected response might be - and this generates new content.
--

Generative language models
Generative language models learn about patterns in language through training data.

Then, given some text, they predict what comes next.

--
Generative image models
Generative image models produce new images using techniques like diffusion.
Then, given a prompt or related imagery, they transform random noise into images or generate images from prompts.

input: Image 
Output: Text/image/video

Input: Text
Output: Text/image/audio/decisions

Generative language models are pattern matching systems

How GenAI works?
Pre-Training:
 - Large amount of Data
 - Billions of parameters
 - Unsupervised learning

Input: prompt "How's it going?"
Transformer: Encoding Component - Decoding Component
Generative Pre-Trained Transformer Model
Output: I'm doing alright, thanks for asking. How are you?

Hallucinations are words or phrases that are generated by the model that are often nonsensical or grammatically incorrect.

How Hallucinations can happen?
Challenges:
- The model is not trained on enouh data
- The model is trained on noisy or dirty data
- The model is not given enough context
- The model is not given enough constraints

Prompt Design: The quality of the input determines the quality of the output

input: prompt
fn: LLM
Output: summarization, writing, Keyword extraction

Model Types
text-to-text
- Applications: Generation, classificatioin, summarization, Translation, (Re)Search, Extraction, Clustering, content editing / rewriting
text-to-image 
- Applications: Image generation, Image editing
text-to-video , text-to-3D
- Application: Video generation, video editing, Game assets

## text-to-task
- Application: Software Agents, Virtual Assistants, Automation

## foundation model
### Data
- Text
- Image
- Speech
- Structured data
- 3D signals
Training: model -- foundation model
pretrained / fine tuned
Adaption: 
Tasks
- Question answering
- Sentiment analysis
- Information extraction
- Image captioning
- Object recoginition
- Instruction following

Model Garden: Vertex AI foundation model
Language:
Foundations
PaLM API for Chat
PaLM API for Text
BERT

Foundations
Embeddings extractor
Stable Diffusion v1-5
BLIP image cpationing 
BLIP VQA
CLIP
OWL_ViT
ViT GPT2